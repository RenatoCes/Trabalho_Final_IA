{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bom2D7NW13_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf009c2-9779-43fa-a864-8637abff0352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=94124a0ff83d70d51ad3ced0ac555a941d939d06c90aafaa4db50cfa0638d79e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python-headless face_recognition\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import face_recognition\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directories = [\n",
        "    \"/content/drive/MyDrive/Reconhecimento_Facial/cadastrados\",\n",
        "    \"/content/drive/MyDrive/Reconhecimento_Facial/frequência\"\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)"
      ],
      "metadata": {
        "id": "GGpXbFqts3xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Resize the output to match the aspect ratio of the video.\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        // Wait for capture to be clicked.\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "        div.remove();\n",
        "\n",
        "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "        return dataUrl;\n",
        "    }\n",
        "    ''')\n",
        "    display.display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "0xDzahG7wXr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/Reconhecimento_Facial/saved_model_3'\n",
        "model = load_model(model_save_path)"
      ],
      "metadata": {
        "id": "2eI5r5fvcvC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import face_recognition\n",
        "import tensorflow as tf\n",
        "\n",
        "cadastrados_path = \"/content/drive/MyDrive/Reconhecimento_Facial/cadastrados\"\n",
        "frequency_path = \"/content/drive/MyDrive/Reconhecimento_Facial/frequência\"\n",
        "model_path = \"/content/drive/MyDrive/Reconhecimento_Facial/saved_model_3\"\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "    image = image.resize((224, 224))\n",
        "    image_array = np.array(image) / 255.0\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    return image_array\n",
        "\n",
        "def add_new_person(user_id, user_name):\n",
        "    if not user_id or not user_name:\n",
        "        print(\"Erro: ID e nome do usuário são obrigatórios.\")\n",
        "        return\n",
        "\n",
        "    image_path = take_photo(filename='new_user_image.jpg')\n",
        "    if is_face_registered(image_path=image_path):\n",
        "        os.remove(image_path)\n",
        "        print(f\"Erro: Rosto já está cadastrado.\")\n",
        "        return\n",
        "\n",
        "    final_image_path = os.path.join(cadastrados_path, f\"{user_id}_{user_name}.jpg\")\n",
        "    shutil.move(image_path, final_image_path)\n",
        "    print(f\"Imagem capturada e salva em {final_image_path}\")\n",
        "\n",
        "    log_file = os.path.join(frequency_path, f\"{user_id}.txt\")\n",
        "    with open(log_file, \"w\") as f:\n",
        "        f.write(f\"Usuário: {user_name}\\nEntrada: \\nSaída: \\n\")\n",
        "    print(f\"Arquivo de log criado para {user_name} em {log_file}\")\n",
        "\n",
        "def add_new_person_from_image(user_id, user_name, image_path):\n",
        "    if not os.path.isfile(image_path):\n",
        "        print(f\"Erro: Caminho da imagem {image_path} não é válido.\")\n",
        "        return\n",
        "\n",
        "    if is_face_registered(image_path=image_path):\n",
        "        print(f\"Erro: Rosto já está cadastrado.\")\n",
        "        return\n",
        "\n",
        "    final_image_path = os.path.join(cadastrados_path, f\"{user_id}_{user_name}.jpg\")\n",
        "    shutil.move(image_path, final_image_path)\n",
        "    print(f\"Imagem salva em {final_image_path}\")\n",
        "\n",
        "    log_file = os.path.join(frequency_path, f\"{user_id}.txt\")\n",
        "    with open(log_file, \"w\") as f:\n",
        "        f.write(f\"Usuário: {user_name}\\nEntrada: \\nSaída: \\n\")\n",
        "    print(f\"Arquivo de log criado para {user_name} em {log_file}\")\n",
        "\n",
        "def is_face_registered(image_path=None):\n",
        "    new_face_array = preprocess_image(image_path)\n",
        "    new_encoding = model.predict(new_face_array)\n",
        "\n",
        "    for filename in os.listdir(cadastrados_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            registered_image_path = os.path.join(cadastrados_path, filename)\n",
        "            registered_face_array = preprocess_image(registered_image_path)\n",
        "            registered_encoding = model.predict(registered_face_array)\n",
        "            distance = np.linalg.norm(registered_encoding - new_encoding)\n",
        "            if distance <= 0.6:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def log_attendance(user_id, user_name):\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    log_file = os.path.join(frequency_path, f\"{user_id}.txt\")\n",
        "    if os.path.exists(log_file):\n",
        "        with open(log_file, \"r+\") as f:\n",
        "            lines = f.readlines()\n",
        "            if 'Entrada: \\n' in lines:\n",
        "                lines[1] = f\"Entrada: {current_time}\\n\"\n",
        "                lines[2] = f\"Saída: {current_time}\\n\"\n",
        "            else:\n",
        "                lines[2] = f\"Saída: {current_time}\\n\"\n",
        "            f.seek(0)\n",
        "            f.writelines(lines)\n",
        "    else:\n",
        "        with open(log_file, \"w\") as f:\n",
        "            f.write(f\"Usuário: {user_name}\\nEntrada: {current_time}\\nSaída: {current_time}\\n\")\n",
        "\n",
        "def recognize_faces_and_log():\n",
        "    captured_image_path = take_photo(filename='captured_image.jpg')\n",
        "    captured_face_array = preprocess_image(captured_image_path)\n",
        "    captured_encoding = model.predict(captured_face_array)\n",
        "\n",
        "    best_match_distance = float('inf')\n",
        "    best_match_user_id = None\n",
        "    best_match_user_name = None\n",
        "\n",
        "    for filename in os.listdir(cadastrados_path):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            user_id, user_name = filename.split('_', 1)\n",
        "            user_name = user_name.replace('.jpg', '')\n",
        "            registered_image_path = os.path.join(cadastrados_path, filename)\n",
        "            registered_face_array = preprocess_image(registered_image_path)\n",
        "            registered_encoding = model.predict(registered_face_array)\n",
        "            distance = np.linalg.norm(registered_encoding - captured_encoding)\n",
        "\n",
        "            if distance < best_match_distance:\n",
        "                best_match_distance = distance\n",
        "                best_match_user_id = user_id\n",
        "                best_match_user_name = user_name\n",
        "\n",
        "    if best_match_user_id is not None and best_match_distance <= 0.6:\n",
        "        log_attendance(best_match_user_id, best_match_user_name)\n",
        "        print(f\"Presença confirmada para {best_match_user_name}\")\n",
        "    else:\n",
        "        print(\"Rosto não reconhecido\")\n",
        "\n",
        "    os.remove(captured_image_path)\n",
        "    time.sleep(2)\n",
        "\n",
        "def clear_frequency_folder():\n",
        "    for filename in os.listdir(frequency_path):\n",
        "        file_path = os.path.join(frequency_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.unlink(file_path)\n",
        "    print(\"Pasta de frequência esvaziada para um novo dia.\")\n",
        "\n",
        "def menu():\n",
        "    while True:\n",
        "        print(\"Sistema de Frequência por Reconhecimento Facial\")\n",
        "        print(\"1. Adicionar nova pessoa (captura de câmera)\")\n",
        "        print(\"2. Adicionar nova pessoa (a partir de imagem)\")\n",
        "        print(\"3. Verificar presença\")\n",
        "        print(\"4. Limpar frequência para um novo dia\")\n",
        "        print(\"5. Sair\")\n",
        "\n",
        "        choice = input(\"Escolha uma opção: \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            user_id = input(\"Digite o ID da pessoa: \")\n",
        "            user_name = input(\"Digite o nome da pessoa: \")\n",
        "            add_new_person(user_id, user_name)\n",
        "        elif choice == \"2\":\n",
        "            user_id = input(\"Digite o ID da pessoa: \")\n",
        "            user_name = input(\"Digite o nome da pessoa: \")\n",
        "            image_path = input(\"Digite o caminho da imagem: \")\n",
        "            add_new_person_from_image(user_id, user_name, image_path)\n",
        "        elif choice == \"3\":\n",
        "            recognize_faces_and_log()\n",
        "        elif choice == \"4\":\n",
        "            clear_frequency_folder()\n",
        "        elif choice == \"5\":\n",
        "            print(\"Saindo do sistema...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Opção inválida. Tente novamente.\")\n",
        "\n",
        "menu()\n"
      ],
      "metadata": {
        "id": "POKOTx2tSk8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d29683df-4006-4b01-81de-e29c6329001d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sistema de Frequência por Reconhecimento Facial\n",
            "1. Adicionar nova pessoa (captura de câmera)\n",
            "2. Adicionar nova pessoa (a partir de imagem)\n",
            "3. Verificar presença\n",
            "4. Limpar frequência para um novo dia\n",
            "5. Sair\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        // Resize the output to match the aspect ratio of the video.\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "        // Wait for capture to be clicked.\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        div.remove();\n",
              "\n",
              "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
              "        return dataUrl;\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imagem capturada e salva em /content/drive/MyDrive/Reconhecimento_Facial/cadastrados/012345_rj.jpg\n",
            "Arquivo de log criado para rj em /content/drive/MyDrive/Reconhecimento_Facial/frequência/012345.txt\n",
            "Sistema de Frequência por Reconhecimento Facial\n",
            "1. Adicionar nova pessoa (captura de câmera)\n",
            "2. Adicionar nova pessoa (a partir de imagem)\n",
            "3. Verificar presença\n",
            "4. Limpar frequência para um novo dia\n",
            "5. Sair\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        // Resize the output to match the aspect ratio of the video.\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "        // Wait for capture to be clicked.\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        div.remove();\n",
              "\n",
              "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
              "        return dataUrl;\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Presença confirmada para rj\n",
            "Sistema de Frequência por Reconhecimento Facial\n",
            "1. Adicionar nova pessoa (captura de câmera)\n",
            "2. Adicionar nova pessoa (a partir de imagem)\n",
            "3. Verificar presença\n",
            "4. Limpar frequência para um novo dia\n",
            "5. Sair\n"
          ]
        }
      ]
    }
  ]
}