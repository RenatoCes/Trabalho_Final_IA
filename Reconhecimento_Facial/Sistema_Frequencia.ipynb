{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM6bNTAFYbk+8Lp0J46UabW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bom2D7NW13_g","executionInfo":{"status":"ok","timestamp":1719800781492,"user_tz":180,"elapsed":9846,"user":{"displayName":"Modesto Neto","userId":"02380053620078749557"}},"outputId":"44955e36-6bc7-4375-9638-840f3f335647"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["!pip install tensorflow opencv-python-headless face_recognition\n","\n","import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from PIL import Image\n","import face_recognition\n","from datetime import datetime\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["directories = [\n","    \"/content/drive/MyDrive/Reconhecimento_Facial/cadastrados\",\n","    \"/content/drive/MyDrive/Reconhecimento_Facial/frequência\"\n","]\n","\n","for directory in directories:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)"],"metadata":{"id":"e52vel-4A3u_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import IPython.display as display\n","from PIL import Image\n","import io\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","    js = Javascript('''\n","    async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","        const capture = document.createElement('button');\n","        capture.textContent = 'Capture';\n","        div.appendChild(capture);\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to match the aspect ratio of the video.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        // Wait for capture to be clicked.\n","        await new Promise((resolve) => capture.onclick = resolve);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getTracks().forEach(track => track.stop());\n","        div.remove();\n","\n","        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n","        return dataUrl;\n","    }\n","    ''')\n","    display.display(js)\n","    data = eval_js('takePhoto({})'.format(quality))\n","    binary = b64decode(data.split(',')[1])\n","    with open(filename, 'wb') as f:\n","        f.write(binary)\n","    return filename"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"7EJGidgp-_f5","executionInfo":{"status":"ok","timestamp":1719800796039,"user_tz":180,"elapsed":14560,"user":{"displayName":"Modesto Neto","userId":"02380053620078749557"}},"outputId":"cacc8200-bcdf-4ba7-886f-c2c40129bb77"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","        const capture = document.createElement('button');\n","        capture.textContent = 'Capture';\n","        div.appendChild(capture);\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to match the aspect ratio of the video.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        // Wait for capture to be clicked.\n","        await new Promise((resolve) => capture.onclick = resolve);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getTracks().forEach(track => track.stop());\n","        div.remove();\n","\n","        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n","        return dataUrl;\n","    }\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["def add_new_person(user_id, user_name):\n","    cadastrados_path = \"/content/drive/MyDrive/Reconhecimento_Facial/cadastrados\"\n","    image_path = take_photo(filename=os.path.join(cadastrados_path, f\"{user_id}_{user_name}.jpg\"))\n","    print(f\"Imagem capturada e salva em {image_path}\")\n","\n","def log_attendance(face_id):\n","    frequency_path = \"/content/drive/MyDrive/Reconhecimento_Facial/frequência\"\n","    now = datetime.now()\n","    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n","\n","    log_file = os.path.join(frequency_path, f\"{face_id}.txt\")\n","    if os.path.exists(log_file):\n","        with open(log_file, \"a\") as f:\n","            f.write(f\"Saída: {current_time}\\n\")\n","    else:\n","        with open(log_file, \"w\") as f:\n","            f.write(f\"Entrada: {current_time}\\n\")\n","\n","def recognize_faces_and_log():\n","    captured_image_path = take_photo(filename='captured_image.jpg')\n","    image = face_recognition.load_image_file(captured_image_path)\n","    face_locations = face_recognition.face_locations(image)\n","    if face_locations:\n","        for face_location in face_locations:\n","            top, right, bottom, left = face_location\n","            face_image = image[top:bottom, left:right]\n","            pil_image = Image.fromarray(face_image).resize((224, 224))\n","            face_array = np.array(pil_image) / 255.0\n","            face_array = np.expand_dims(face_array, axis=0)\n","\n","            predictions = model.predict(face_array)\n","            face_id = np.argmax(predictions)\n","\n","            confidence = np.max(predictions)\n","            if confidence > 0.5:\n","                log_attendance(face_id)\n","                print(\"Presença confirmada\")\n","            else:\n","                print(\"Rosto não reconhecido\")\n","    else:\n","        print(\"Nenhuma face encontrada na imagem capturada.\")\n"],"metadata":{"id":"EZ5TFxqIDX9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_save_path = '/content/drive/MyDrive/Reconhecimento_Facial/saved_model'\n","model = load_model(model_save_path)\n"],"metadata":{"id":"sC1WWIc_DnmL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def menu():\n","    print(\"Sistema de Frequência por Reconhecimento Facial\")\n","    print(\"1. Adicionar nova pessoa\")\n","    print(\"2. Verificar presença\")\n","    choice = input(\"Escolha uma opção: \")\n","\n","    if choice == \"1\":\n","        user_id = input(\"Digite o ID da nova pessoa: \")\n","        user_name = input(\"Digite o nome da nova pessoa: \")\n","        add_new_person(user_id, user_name)\n","    elif choice == \"2\":\n","        recognize_faces_and_log()\n","    else:\n","        print(\"Opção inválida\")\n","\n","menu()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"vlSv5DsaDrn9","executionInfo":{"status":"ok","timestamp":1719801192207,"user_tz":180,"elapsed":9112,"user":{"displayName":"Modesto Neto","userId":"02380053620078749557"}},"outputId":"9c3caf3f-9292-4e73-aaec-266d2afa1289"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Sistema de Frequência por Reconhecimento Facial\n","1. Adicionar nova pessoa\n","2. Verificar presença\n","Escolha uma opção: 2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function takePhoto(quality) {\n","        const div = document.createElement('div');\n","        const capture = document.createElement('button');\n","        capture.textContent = 'Capture';\n","        div.appendChild(capture);\n","\n","        const video = document.createElement('video');\n","        video.style.display = 'block';\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","        document.body.appendChild(div);\n","        div.appendChild(video);\n","        video.srcObject = stream;\n","        await video.play();\n","\n","        // Resize the output to match the aspect ratio of the video.\n","        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","        // Wait for capture to be clicked.\n","        await new Promise((resolve) => capture.onclick = resolve);\n","\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        stream.getTracks().forEach(track => track.stop());\n","        div.remove();\n","\n","        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n","        return dataUrl;\n","    }\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Nenhuma face encontrada na imagem capturada.\n"]}]}]}